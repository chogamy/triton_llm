version: '3.8'

services:
  triton_server:
    image: triton_llm_server
    build:
      context: .
      dockerfile: dockerfile
    ports:
      - "8000:8000"  # HTTP
      - "8001:8001"  # gRPC
      - "8002:8002"  # Metrics
    volumes:
      - <YOUR_MODEL_PATH>:/triton_llm/weights/gemma-3-12b-it
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0', '1', '2', '3']
              capabilities: [gpu]
    command: ["tritonserver", "--model-repository=/triton_llm/models", "--disable-auto-complete-config"]